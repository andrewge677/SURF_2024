# SURF 2024
CSU Channel Islands SURF Summer Research <br>

Student Researchers: <br>
- Andrew Ge <br>
- Sheldon Peters <br>
- Alejandro Antonio <br>

Faculty Mentors: <br>
- Dr. Bahareh Abbasi <br>
- Dr. Jason Isaacs <br>

Despite significant advancements in robotics, achieving full autonomy for robots in various domains, such as manufacturing, remains a significant challenge. This SURF project aims to develop a mechanism that enhances the process of teaching a robot to perform object manipulation tasks through interaction with a human expert. By leveraging the capabilities of Large Language Models (LLMs) to comprehend human conversations, we strive to ensure seamless and effective human-robot interaction. 

While most of the previous work focuses on using LLMs for task planning, here we take a new approach to use it for understanding of human expertâ€™s demonstration using multimodal data and convert it to an actionable program for a robot.

We hope the applications of this work can be utilized in various fields such as healthcare, emergency response, manufacturing, hospitality, and more.

In this project, we utilize Sawyer, a robotic arm equipped with a state-of-the-art vision language model, ChatGPT-4o as its brain and planner. This VLM is capable of processing and understanding language and vision, and using several external resources while operating within Robot Operating System (ROS). With this architecture, our team hopes to train the LLM not only to perform a task, but also to train new users through a combination of  expert instructions and LLM processing.

Summer Surf 2024 Technical Documentation: <br>
https://docs.google.com/document/d/1eSpenHqlkqRHNvWpHtizz2qoFf9gMP56MRsDQyWa9ww/edit?usp=sharing

Acknowledgements: <br>
- Maximilian Seligman <br>
- SURF Staff <br>
- Cobalt Team Representatives <br>

Credits: <br>
OpenAI, Intel, Python, Rviz, ROS, Ubuntu, Google Speech API and Rethink Robotics
