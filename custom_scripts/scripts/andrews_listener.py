#!/usr/bin/env python

# speech to text node that does not use internet
# may be faster than API requests but may not be as accurate

# current problems:
# - creates new thread every time recording is made. if performance issues are found, may need to modify for efficiency
# - sample rate was from AI generated code, presumably from some online example, may not be optimal
# - speech variable is stored from less accurate recognize_google, but not used. Kept because may be useful sometime later
# - there are python methods that remove silence from WAV files, need to use
# - will only kill child thread appropriately if ctrl+C, otherwise will leave zombie process (use rospy_on_shutdown or whatever)

import speech_recognition as sr

import sounddevice as sd
import numpy as np
import scipy.io.wavfile as wav
import threading
import os
import rospy
from std_msgs.msg import String

# Set the sample rate
fs = 44100  # Sample rate
# Initialize a list to hold the audio data
recording = []
# Create a threading event
stop_recording = None
recording_thread = None

def shutdown_hook():
    if not recording_thread is None:
        print("Killing child process.")
        stop_recording.set()
        recording_thread.join()
    print("Exiting recording program.")

def listen_and_transcribe(transcription_node):
    try:
        def record_audio():
            while not stop_recording.is_set():
                # Record audio for 1 second
                myrecording = sd.rec(int(1 * fs), samplerate=fs, channels=2, dtype='int16')
                sd.wait()  # Wait for the recording to finish

                # Append the recording to our list of recordings
                recording.append(myrecording)

            # Concatenate all the recordings into one array
            recording_concat = np.concatenate(recording, axis=0)

            # Save as a WAV file
            # wav.write('../sound_files/output.wav', fs, recording_concat)                      # uncomment if you need wav files for google speech to text api

        # Create a recognizer instance
        r = sr.Recognizer()

        # Create a microphone instance
        mic = sr.Microphone()

        num_failures = 0

        while num_failures < 10:
            with mic as source:

                # start recording
                recording = []
                stop_recording = threading.Event()
                recording_thread = threading.Thread(target=record_audio)
                recording_thread.start()

                print("Listening...")
                audio = r.listen(source)

                # Try to recognize the speech
                try:
                    speech = r.recognize_google(audio)                          # speech generated by recognize_google not as robust as Google API call, not used here
                    
                    if(speech == "quit"):
                        break
                    
                    print("Speech detected: " + speech)    
                    # signal thread to save and end
                    stop_recording.set()      

                    transcription_node.publish(speech) 

                    print("WAV Recording saved.")  

                    num_failures = 0       

                except sr.UnknownValueError:
                    print("No speech detected.")
                    # signal thread to save and end
                    stop_recording.set()
                    # delete recording because no speech detected if exists
                    if os.path.exists("recordings/output.wav"):
                        os.remove("recordings/output.wav")
                    num_failures += 1

                except sr.RequestError:
                    print("Could not request results from Google Speech Recognition service")
                
                # wait for thread to end
                recording_thread.join()

    except KeyboardInterrupt:                           # likely change this to RosInterruptException
        if not recording_thread is None:
            print("Killing child process.")
            stop_recording.set()
            recording_thread.join()
        print("Exiting recording program.")

def main():
    global transcription_node
    rospy.init_node('sr_listener', anonymous=True)
    transcription_node = rospy.Publisher('/transcription', String, queue_size=10)

    rospy.on_shutdown(shutdown_hook)
    listen_and_transcribe(transcription_node)

if __name__ == '__main__':
    main()